1
00:00:00,790 --> 00:00:07,300
In this demo, we're going to look at updates and rollbacks and for deployments in Kubernetes.

2
00:00:07,840 --> 00:00:13,120
So in the previous demo, we used a deployment definition file, which is located in the deployment

3
00:00:13,120 --> 00:00:15,160
directory of our project folder.

4
00:00:15,490 --> 00:00:19,000
The name of the deployment is my app deployment.

5
00:00:19,510 --> 00:00:22,840
And we have updated the file to use six replicas.

6
00:00:22,990 --> 00:00:27,700
All year it was three and it is using an index image.

7
00:00:28,090 --> 00:00:33,010
So to create this deployment, we will use the Create Deployment command.

8
00:00:33,160 --> 00:00:38,860
But before that, let's quickly check and make sure that there are no objects created in the cluster.

9
00:00:39,740 --> 00:00:41,120
Okay, so that looks good.

10
00:00:41,510 --> 00:00:48,170
So I'm going to run the cube cutter, create command with the dash F option to specify the deployment

11
00:00:48,170 --> 00:00:50,180
YAML as the file.

12
00:00:50,360 --> 00:00:53,510
So once we run this command, the deployment is created.

13
00:00:53,780 --> 00:01:01,520
Now, let's make use of a new command called the Rollout Status Command with the deployment name to

14
00:01:01,520 --> 00:01:03,650
check the status of the deployment.

15
00:01:04,190 --> 00:01:11,150
So as soon as I run this command, I see that the deployment, my app deployment has been successfully

16
00:01:11,150 --> 00:01:11,930
rolled out.

17
00:01:12,560 --> 00:01:20,030
Now, if we had run this command more quickly, like right after we ran the command to create the deployment,

18
00:01:20,150 --> 00:01:22,340
we would have seen a different status.

19
00:01:22,550 --> 00:01:25,750
So let's quickly delete this deployment.

20
00:01:25,760 --> 00:01:31,760
And what I'm going to do now is I'm going to create the deployment again and I'm going to quickly run

21
00:01:31,760 --> 00:01:33,830
the status command right after I do it.

22
00:01:35,070 --> 00:01:41,520
As soon as I run this command, it will show you the status of each replica which is being brought up.

23
00:01:41,520 --> 00:01:49,230
So remember that we have used six replicas in total and as soon as we run the status command after deleting

24
00:01:49,230 --> 00:01:55,980
the deployment, we see that it tries to bring up the pod one at a time.

25
00:01:56,640 --> 00:02:03,620
So here we have zero out of six and then one of those six, two out of six, etc. So until all the six

26
00:02:03,630 --> 00:02:07,860
pods are up and running, you'll see a status message related to that.

27
00:02:07,860 --> 00:02:13,950
And only after all the pods have been deployed successfully will Kubernetes consider the deployment

28
00:02:13,950 --> 00:02:15,480
to be successful.

29
00:02:15,840 --> 00:02:22,080
So once deployed, we use another command to see the history of the deployment.

30
00:02:22,080 --> 00:02:25,190
And for this we will use the same command as before.

31
00:02:25,200 --> 00:02:29,940
But instead of status, we will use the rollout history command.

32
00:02:33,280 --> 00:02:40,810
Now you can see that the my app deployment has one revision, which is the one that we just did that

33
00:02:40,810 --> 00:02:42,640
was creating the deployment itself.

34
00:02:42,970 --> 00:02:50,500
And there is also a column called Change Costs, which you'll notice that has there is no change cost

35
00:02:50,500 --> 00:02:51,430
specified.

36
00:02:52,030 --> 00:02:59,110
And that is because we did not specifically ask it to record the cause of change while we created the

37
00:02:59,110 --> 00:02:59,830
deployment.

38
00:03:00,590 --> 00:03:02,510
So let's go back and fix that.

39
00:03:02,510 --> 00:03:05,360
So we'll delete the deployment again.

40
00:03:10,060 --> 00:03:13,450
Let's wait for the port to be terminated.

41
00:03:13,450 --> 00:03:18,880
So now it's in a in a terminating state and let's wait for all of them to go away.

42
00:03:19,480 --> 00:03:24,070
So now that all of them have been deleted, I'm going to run the same command as before.

43
00:03:24,070 --> 00:03:29,200
But this time I'm going to use the dash dash record option.

44
00:03:29,200 --> 00:03:34,810
The record option instructs Kubernetes to record the cause of change.

45
00:03:34,930 --> 00:03:41,230
So we will execute that command now and again, I'll run the rule out status command to watch the status

46
00:03:41,230 --> 00:03:46,390
of deployment and wait for all the ports to be up and for the deployment to be successful.

47
00:03:50,240 --> 00:03:52,850
And now let's run the history command again.

48
00:03:52,850 --> 00:03:58,880
And this time you'll see that against the revision there is a change clause which is mentioned, which

49
00:03:58,880 --> 00:04:03,230
is essentially the same command that we ran to create the deployment.

50
00:04:03,230 --> 00:04:10,310
But because we use the DASH record option, it is recording the command here.

51
00:04:10,760 --> 00:04:14,120
So now let us try to make a change to the deployment.

52
00:04:14,660 --> 00:04:19,970
So first let's run the Colonel, describe a command with the name of the deployment.

53
00:04:22,220 --> 00:04:27,860
And this pulls up the additional information and you'll see that in the annotations section, it has

54
00:04:27,860 --> 00:04:32,270
recorded the command that we used to run this to create this deployment.

55
00:04:32,480 --> 00:04:36,080
And we know that it is running six replicas.

56
00:04:36,170 --> 00:04:41,930
And if you scroll down, you'll see that the image of this container of this deployment is engine X.

57
00:04:41,930 --> 00:04:43,910
So let's make a change to that.

58
00:04:46,150 --> 00:04:50,590
And for this I'll make use of the edit deployment command.

59
00:04:50,710 --> 00:04:58,000
And I'm also going to use the dash record option so that the cause of change is tracked in the revision

60
00:04:58,000 --> 00:04:58,750
history.

61
00:04:59,020 --> 00:05:03,520
So what I'm going to do now is I'm going to look up image.

62
00:05:04,120 --> 00:05:06,940
And currently it is set to engine X.

63
00:05:07,180 --> 00:05:09,760
So we will change this to a lower version.

64
00:05:10,120 --> 00:05:13,270
So this is using the latest version of Engine X currently.

65
00:05:13,270 --> 00:05:18,040
And what we'll do is we will change it to another version, a lower version.

66
00:05:18,040 --> 00:05:21,790
And for that let's make use of the Docker hub documentation.

67
00:05:21,820 --> 00:05:25,090
So here I'm at Docker Hub and I'm looking at.

68
00:05:25,740 --> 00:05:33,130
And Gen X, and you'll see that the current version, since we did not specify a target, is 1.19 as

69
00:05:33,130 --> 00:05:34,030
of this recording.

70
00:05:34,030 --> 00:05:36,160
And let us make use of an older version.

71
00:05:36,160 --> 00:05:37,420
1.18.

72
00:05:37,750 --> 00:05:39,220
So back to the terminal.

73
00:05:39,220 --> 00:05:41,980
I'm going to change the version to 1.18.

74
00:05:42,100 --> 00:05:45,790
And for that I'll add a colon and I'll mention the version number here.

75
00:05:46,950 --> 00:05:53,730
And once I'm done with the changes, I'll use the WQ to save and exit the editor.

76
00:05:53,850 --> 00:06:02,010
And now if you're on the status command, you will see a familiar screen where it is bringing up the

77
00:06:02,010 --> 00:06:02,940
new pods.

78
00:06:03,180 --> 00:06:08,460
But you'll also notice that in the screen we see that the old pods are getting terminated.

79
00:06:08,640 --> 00:06:12,870
So one after the other, the new pods are being created with a new image.

80
00:06:13,200 --> 00:06:15,840
Whereas old pods are getting terminated.

81
00:06:16,050 --> 00:06:23,610
So since the default update strategy is set to rolling update Kubernetes deployments are intelligent

82
00:06:23,610 --> 00:06:29,580
enough to make sure that there are some running pods in the system so that the end users are not affected.

83
00:06:29,580 --> 00:06:32,430
And it does the update one after the other.

84
00:06:32,910 --> 00:06:39,660
So now let's run a cube described command against the deployment and you'll see the same thing under

85
00:06:39,660 --> 00:06:41,460
the events section as well.

86
00:06:41,670 --> 00:06:48,930
So you can see that the older replica sets have been scaled down along with the replica set IDs, which

87
00:06:48,930 --> 00:06:52,210
were running the older image and the new ones are scaled up.

88
00:06:52,230 --> 00:06:59,190
And here we can see the revision and the cause of change, which is cube edit deployment, which we

89
00:06:59,190 --> 00:07:00,570
ran to change the image.

90
00:07:00,840 --> 00:07:08,460
And here we take a look at the image quickly and we can see that it is running engine X 1.18.

91
00:07:09,750 --> 00:07:10,050
All right.

92
00:07:10,050 --> 00:07:13,830
So now let's make yet another change to our deployment.

93
00:07:14,010 --> 00:07:17,640
So right now it's running engine X version 1.18.

94
00:07:17,670 --> 00:07:21,820
Say we have a requirement to use a different image instead of this.

95
00:07:21,900 --> 00:07:28,950
So one way to do that is to use the shuttle edit deployment command and edit the image name within the

96
00:07:28,950 --> 00:07:30,510
YAML file that opens.

97
00:07:31,320 --> 00:07:38,310
Another way to do is to use another command called Cube coddle, set image deployment and the name of

98
00:07:38,310 --> 00:07:41,250
the deployment, which is my app deployment.

99
00:07:41,550 --> 00:07:49,130
And here I'm going to use the name of the container, which is Engine X, and this is a key value format

100
00:07:49,140 --> 00:07:50,730
way of specifying the value.

101
00:07:50,740 --> 00:07:55,010
So this should have the value of the new version that we're going to set.

102
00:07:55,080 --> 00:07:57,630
So let's make use of the Docker hub page.

103
00:07:57,690 --> 00:08:02,880
And the new version that we will use is say 1.18 dash PO.

104
00:08:12,130 --> 00:08:17,020
Again, I'm going to make use of the record command the record option while I do this.

105
00:08:17,020 --> 00:08:19,720
So the changes are recorded in the rollout history.

106
00:08:19,840 --> 00:08:26,590
So now let's run a quick status command and we can see that the older replicas are getting terminated,

107
00:08:27,160 --> 00:08:34,650
which is for version 1.18, and we should have new replicas up and running for the version 1.18 pearl.

108
00:08:35,140 --> 00:08:41,110
So a quick look at the history shows us that it's all set and we have the new version, which is version

109
00:08:41,110 --> 00:08:46,060
number three, where we update the image using the set image command.

110
00:08:46,630 --> 00:08:53,350
So let's quickly run the Get parts command and make sure that all the six parts are running.

111
00:08:53,830 --> 00:08:59,290
So let's say there is an issue with this new image that we used and it's not working well for the end

112
00:08:59,290 --> 00:08:59,980
users.

113
00:09:00,190 --> 00:09:06,120
We can revert back to the previous version by using the cuddle undo command.

114
00:09:06,130 --> 00:09:12,310
So right now we are on a revision three and we want to move to revision two, which has the engine x

115
00:09:12,580 --> 00:09:14,290
1.18 version.

116
00:09:14,500 --> 00:09:20,710
And to do this we can run the rollout undo command with the name of the deployment.

117
00:09:24,840 --> 00:09:28,470
So again, let's run, cuddle status, command.

118
00:09:28,740 --> 00:09:34,920
And we see that it is making the change and it is bringing down the older replicas of revision number

119
00:09:34,920 --> 00:09:41,700
three and then reverting back to revision number two, which runs the engine x 1.18 image.

120
00:09:42,810 --> 00:09:48,780
Let's run a code will describe deployment command to make sure that this command in fact switched to

121
00:09:48,780 --> 00:09:49,860
the correct image.

122
00:09:50,220 --> 00:09:53,910
So it has reverted back to engine X 1.18 image.

123
00:09:54,560 --> 00:09:59,600
So now let's take a quick look at the rollout history and see what is recorded there.

124
00:10:00,140 --> 00:10:04,060
Now, you will see that we still have three revisions in total.

125
00:10:04,070 --> 00:10:08,240
There is a new revision which is now created, which is number four.

126
00:10:08,480 --> 00:10:11,810
But the revision number two is gone.

127
00:10:12,110 --> 00:10:18,140
Now, that's because the fourth revision, which is the new revision, is essentially the just the same

128
00:10:18,140 --> 00:10:19,490
as the second revision.

129
00:10:20,090 --> 00:10:25,910
So it's reverted back to the same state that deployment was on when it was at revision two.

130
00:10:26,360 --> 00:10:33,110
So essentially revision two has become the latest revision, but it has changed the revision number

131
00:10:33,110 --> 00:10:34,550
from 2 to 4.

132
00:10:35,030 --> 00:10:40,550
And this is the same command that was recorded for revision two as well.

133
00:10:41,470 --> 00:10:43,900
Now let's try out another scenario.

134
00:10:43,900 --> 00:10:49,930
So I'm going to use the cube to edit command again and make some more changes to our deployment.

135
00:10:49,960 --> 00:10:56,830
Now we know that right now the image should be on 1.18 because we reverted in the last step.

136
00:10:57,070 --> 00:11:02,710
So now I'm going to make a change for the next container to use an image that does not exist.

137
00:11:02,890 --> 00:11:10,090
So let me put something random here, such as does not exist, and I'm going to save this file.

138
00:11:10,600 --> 00:11:13,840
And we'll see the status now.

139
00:11:16,410 --> 00:11:23,910
So now you can see that the rollout status is stuck with this message that says waiting for a rollout

140
00:11:23,910 --> 00:11:29,440
to finish and that three out of five new replicas have been updated.

141
00:11:29,460 --> 00:11:35,970
It's going to stay there as it's trying to update to an image that does not exist and it's not able

142
00:11:35,970 --> 00:11:40,260
to pull that image from Docker Hub so the containers would fail.

143
00:11:40,620 --> 00:11:44,670
So as a result, it will not successfully complete those deployment.

144
00:11:45,390 --> 00:11:47,220
Now, let's go back and check.

145
00:11:47,640 --> 00:11:50,400
We run the queue to get deployment command.

146
00:11:53,610 --> 00:11:55,530
And we provide the name of the deployment.

147
00:11:56,660 --> 00:12:02,360
And here we see that the ready state for this deployment is now five out of six.

148
00:12:02,910 --> 00:12:05,960
Now up to date is three and available is five.

149
00:12:06,230 --> 00:12:11,090
And let's also quickly run, cuddle, get parts command.

150
00:12:12,900 --> 00:12:17,700
And here you'll notice that the number of pods which are running is actually five.

151
00:12:17,910 --> 00:12:25,980
So here the deployment has terminated one of the existing pods on version 1.18, and it has tried to

152
00:12:25,980 --> 00:12:29,400
create three new pods with the new version of the image.

153
00:12:29,880 --> 00:12:31,320
The one that does not exist.

154
00:12:31,320 --> 00:12:34,020
And that's why they are all in an error state.

155
00:12:34,530 --> 00:12:38,690
So the status of the new pods are image pulled back off.

156
00:12:38,700 --> 00:12:44,550
So all of these three have failed because the image by that name that we specified does not exist on

157
00:12:44,550 --> 00:12:45,370
Docker Hub.

158
00:12:45,390 --> 00:12:51,600
And as a result, it will keep the deployment in its current state until it is able to fetch this new

159
00:12:51,600 --> 00:12:52,980
image from Docker Hub.

160
00:12:53,900 --> 00:13:01,130
So even though we have specified a wrong image and there are three new pods which are trying to load

161
00:13:01,130 --> 00:13:07,820
the new image, the application is not impacted and the end users will still be able to access the application

162
00:13:07,820 --> 00:13:11,000
on the old five running pods.

163
00:13:11,150 --> 00:13:19,220
And this is because since we set the strategy to rolling upgrade, Kubernetes will only downgrade or

164
00:13:19,220 --> 00:13:25,940
destroy the older pods once we have sufficient newer pods available.

165
00:13:26,270 --> 00:13:30,710
So now let's take a look at the revision history and you will see that a new revision, which is revision

166
00:13:30,710 --> 00:13:33,080
number five, is recorded as well.

167
00:13:33,080 --> 00:13:39,560
So now as a final step, let us do an undo deployment operation so that it goes from revision number

168
00:13:39,560 --> 00:13:46,250
five back to revision number four and fix the name of the image back to engine X 1.18.

169
00:13:46,430 --> 00:13:50,480
So for that, I'm going to use the rollout undo command again.

170
00:13:51,560 --> 00:13:54,890
And let's run the rollout status real quickly.

171
00:13:54,890 --> 00:13:57,980
And now you'll see that it is successful.

172
00:13:58,250 --> 00:14:00,230
So let's check the status of the pods.

173
00:14:00,230 --> 00:14:06,860
And we see that the the one that it had to recreate has been created 12 seconds ago and the remaining

174
00:14:06,860 --> 00:14:13,730
five pods were already in the correct version of 1.18, and it terminated the three new pods, which

175
00:14:13,730 --> 00:14:16,400
was trying to make use of the wrong image.

176
00:14:17,070 --> 00:14:25,320
So now let us run a describe command and we will see that our application is now on the correct version,

177
00:14:25,320 --> 00:14:27,840
which is in the next 1.18.

178
00:14:28,820 --> 00:14:30,050
And everything's good.

179
00:14:30,890 --> 00:14:32,600
Well, that's it for now.

180
00:14:32,600 --> 00:14:34,880
And I will see you in the next lecture.

